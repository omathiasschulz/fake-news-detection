
4. DESENVOLVIMENTO

4.1 DADOS DISPONÍVEIS (Pronto)

4.2 TRATAMENTO DOS DADOS (Pronto)

4.3 RECURSOS UTILIZADOS

4.3.1 Bibliotecas (Pronto)

4.3.1.1  Numpy (Pronto)
4.2.1.2  Pandas (Pronto)
4.3.1.3  Matplotlib (Pronto)
4.3.1.4  Seaborn (Pronto)
4.3.1.5  NLTK (Pronto)
4.3.1.6  Gensim (Pronto)
4.3.1.7  Keras (Pronto)

4.3.1 Funções de Ativação
(TODO) Texto quase pronto - Falta explicar as funções de ativação que serão utilizadas

Começar com a função ReLU e depois passar para outras funções de ativação no caso da ReLU não forneça resultados ótimos
De uma forma geral devemos preferir ELU > leaky ReLU > ReLU >> tanh > sigmoide
As funções ReLU, Leaky ReLU e ELU são muito melhores do que as funções sigmoidais
Quanto às ativações sigmoidais, a função TanH é significantemente melhor do que a Sigmoide
-- Sigmóide
Funciona melhor no caso de classificadores
Às vezes é evitada devido ao problema de Vanishing Gradient
-- Tanh
Às vezes é evitada devido ao problema de Vanishing Gradient
-- ReLU
Função de ativação geral, utilizada na maioria dos casos atualmente
Deve ser usada apenas nas camadas ocultas
-- Leaky ReLU
Boa para casos com neurônios deficientes nas redes

4.3.2 Validação Cruzada
(TODO)

4.3.4 Algoritmos de otimização
(TODO)

4.3.4.1 ADAM
(TODO)

4.4 REPRESENTAÇÃO NUMÉRICA DOS DADOS
(TODO)

4.5 ÍNDICES PARA ANÁLISE DA QUALIDADE DA DETECÇÃO
(TODO)
=> Exemplo RMSE, mas ainda não sei quais vou usar certo

5. RESULTADOS
(TODO)
=> LSTM => Keras 'Biblioteca de aprendizado profundo para Theano e TensorFlow'
=> LSTM => scikit-learn 'Aprendizado de máquina fácil de usar e de uso geral em Python'



# Trabalhos correlatos - Métricas e funções de ativação

## 1

Precision
Recall
F1_score
Accuracy
Confusion Matrix

A saída do LSTM bidirecional passou por três camadas densas (512, 128, 4 unidades) separadas por um dropout.
Usando a função de ativação soft-max na camada de saída, o resultado é uma classificação de postura (não relacionada, concordar, discordar ou discutir)
Adam optimizer

## 2

precision recall fl-score support
confusion matrix
Accuracy

A matriz de confusão tem a forma mostrada na Tabela 2. 0 é negativo e 1 é positivo. 
Os seguintes termos foram usados: Verdadeiro negativo (TN), ou seja, a previsão foi negativa e os casos de teste também foram negativos; 
Positivo verdadeiro (TP), ou seja, a previsão foi positiva e os casos de teste também foram positivos; 
Falso negativo (FN), ou seja, a previsão foi negativa, mas os casos de teste foram realmente positivos; 
e, finalmente, Falso Positivo (FP), ou seja, a previsão foi positiva, mas os casos de teste foram realmente negativos. 

A Accuracy / precisão foi descrita conforme a fórmula: Precisão = (TP + TN) / Total

Precision of a class
how many of a class were predicted correctly / how many of the same class we totally predicted

Recall of a class
how many of a class were predicted correctly / how many of the same class are actually present

F1-Score of a class
Harmonic mean of precision and recall value

Support of a class
How many actual values of the class we had

Loss: For loss of this model Refer Table 4. Binary Cross Entropy Loss and its minimized version using Adam Optimizer is depicted in Figures 6(a) and 6(b) respectively.


Basic loss was based on Binary Cross Entropy Loss.

Adam Optimizer

Outras camadas incluem camada 1D de eliminação espacial, camada LSTM, camada densa (com RELU de ativação), camada de eliminação e a camada densa de saída, Sigmóide, com otimizador Adam. 
O algoritmo de otimização Adam atualiza iterativamente os pesos dos parâmetros da rede com base em certos dados de treinamento.

## 3

Confusion matrix

Hashing vectorizer
Outro tipo usado na classificação de texto é o vetorizador de Hashing, que exige menos memória e mais rápido porque usa Hashes em vez de tokens. Ele fornece resultados de precisão melhorados do que o vetorizador TF-IDF usando Multinomial Naïve Bayes.

Precision

Accuracy

Recall
Recall also known as sensitivity is the fraction of significant instances that have been retrieved over the total amount of relevant instances.

F1-SCORE
F  score also F-score or F-measure is a measure of a test's accuracy for binary classification.


Main functions in CNN are:
ReLU
Stands for Rectified Linear Unit for a non-linear operation. The output is ƒ(x) = max (0, x).
REL U’s use is to introduce non-linearity in our CNN

## 4

Nada de mais

## 5

Para a rede LSTM, definimos o comprimento máximo de entrada como 500 com pós-preenchimento por zeros. 
Cada sequência de entrada está embutida em vetores de 64 dimensões. 
Cada uma das entradas incorporadas é então alimentada em uma rede LSTM com 100 unidades neurais. 
A saída da rede LSTM é então passada para uma rede densa unidimensional com sigmóide como função de ativação. 
O modelo é então compilado com o otimizador adam e binary_crossentropy usado como uma função de perda. 
O modelo é então equipado com batch_size definido para 64 e 100 épocas.
